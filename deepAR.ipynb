{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e50786",
   "metadata": {},
   "source": [
    "# DeepAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc003e6",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b126d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import util\n",
    "from datetime import date\n",
    "import argparse\n",
    "from torch.utils.tensorboard.writer import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5782495",
   "metadata": {},
   "source": [
    "## Define Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ee6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        '''\n",
    "        Gaussian Likelihood Supports Continuous Data\n",
    "        Args:\n",
    "        input_size (int): hidden h_{i,t} column size\n",
    "        output_size (int): embedding size\n",
    "        '''\n",
    "        super(Gaussian, self).__init__()\n",
    "        self.mu_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.sigma_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # initialize weights\n",
    "        # nn.init.xavier_uniform_(self.mu_layer.weight)\n",
    "        # nn.init.xavier_uniform_(self.sigma_layer.weight)\n",
    "\n",
    "    def forward(self, h):\n",
    "        _, _, hidden_size = h.size()\n",
    "        sigma_t = torch.log(1 + torch.exp(self.sigma_layer(h))) + 1e-6\n",
    "        sigma_t = sigma_t.squeeze(0)\n",
    "        mu_t = self.mu_layer(h).squeeze(0)\n",
    "        return mu_t, sigma_t\n",
    "\n",
    "\n",
    "class NegativeBinomial(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Negative Binomial Supports Positive Count Data\n",
    "        Args:\n",
    "        input_size (int): hidden h_{i,t} column size\n",
    "        output_size (int): embedding size\n",
    "        '''\n",
    "        super(NegativeBinomial, self).__init__()\n",
    "        self.mu_layer = nn.Linear(input_size, output_size)\n",
    "        self.sigma_layer = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, h):\n",
    "        _, _, hidden_size = h.size()\n",
    "        alpha_t = torch.log(1 + torch.exp(self.sigma_layer(h))) + 1e-6\n",
    "        mu_t = torch.log(1 + torch.exp(self.mu_layer(h)))\n",
    "        return mu_t, alpha_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c642ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_sample(mu, sigma):\n",
    "    '''\n",
    "    Gaussian Sample\n",
    "    Args:\n",
    "    ytrue (array like)\n",
    "    mu (array like)\n",
    "    sigma (array like): standard deviation\n",
    "\n",
    "    gaussian maximum likelihood using log \n",
    "        l_{G} (z|mu, sigma) = (2 * pi * sigma^2)^(-0.5) * exp(- (z - mu)^2 / (2 * sigma^2))\n",
    "    '''\n",
    "    ypred = mu + torch.randn(mu.size(), dtype=mu.dtype, device=mu.device) * sigma\n",
    "    return ypred\n",
    "\n",
    "\n",
    "def negative_binomial_sample(mu, alpha):\n",
    "    '''\n",
    "    Negative Binomial Sample\n",
    "    Args:\n",
    "    ytrue (array like)\n",
    "    mu (array like)\n",
    "    alpha (array like)\n",
    "\n",
    "    maximuze log l_{nb} = log Gamma(z + 1/alpha) - log Gamma(z + 1) - log Gamma(1 / alpha)\n",
    "                - 1 / alpha * log (1 + alpha * mu) + z * log (alpha * mu / (1 + alpha * mu))\n",
    "\n",
    "    minimize loss = - log l_{nb}\n",
    "\n",
    "    Note: torch.lgamma: log Gamma function\n",
    "    '''\n",
    "    var = mu + mu * mu * alpha\n",
    "    ypred = mu + torch.randn(mu.size(), dtype=mu.dtype, device=mu.device) * torch.sqrt(var)\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc455e",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4628b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAR(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_size, hidden_size,\n",
    "                 output_size, num_layers, likelihood=\"g\"):\n",
    "        '''The DeepAR model\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        feature_size\n",
    "            The number of features in the input\n",
    "        hidden_size\n",
    "            The size of the hidden vectors\n",
    "        output_size\n",
    "            The size of the output vectors\n",
    "        num_layers\n",
    "            The number of lstm layers\n",
    "        likelihood\n",
    "            The likelihood function to use:\n",
    "                gaussian or negative binomial\n",
    "        '''\n",
    "        super(DeepAR, self).__init__()\n",
    "\n",
    "        self.encoder = nn.LSTM(feature_size+output_size, hidden_size,\n",
    "                               num_layers, bias=True, batch_first=True)\n",
    "        if likelihood == \"g\":\n",
    "            self.likelihood_layer = Gaussian(hidden_size, output_size)\n",
    "        elif likelihood == \"nb\":\n",
    "            self.likelihood_layer = NegativeBinomial(hidden_size, output_size)\n",
    "        self.likelihood = likelihood\n",
    "\n",
    "    def forward(self, Xp, yp, Xf):\n",
    "        '''Forward Pass\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Xp\n",
    "            The past covariates\n",
    "        yp\n",
    "            The past output variables\n",
    "        Xf\n",
    "            The future covariates\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Tuple\n",
    "            \n",
    "        '''\n",
    "        batch_size, history, num_features = Xp.size()\n",
    "        _, horizon, _ = Xf.size()\n",
    "        _, _, num_outputs = yp.size()\n",
    "        ypred = []\n",
    "        mus = []\n",
    "        sigmas = []\n",
    "        h, c = None, None\n",
    "        for s in range(history + horizon):\n",
    "            if s == 0:\n",
    "                yin = yp[:, s:s+1, :].new_zeros([batch_size, 1, num_outputs])\n",
    "                xin = Xp[:, s:s+1, :]\n",
    "            elif 0 < s < history:\n",
    "                yin = yp[:, s-1:s, :]\n",
    "                xin = Xp[:, s:s+1, :]\n",
    "            elif s == history:\n",
    "                yin = yp[:, s-1:s, :]\n",
    "                xin = Xf[:, s-history:s-history+1, :]\n",
    "            else:\n",
    "                xin = Xf[:, s-history:s-history+1, :]\n",
    "            \n",
    "            # pass through the LSTM\n",
    "            inp = torch.cat([xin, yin], dim=2)\n",
    "            if h is None and c is None:\n",
    "                out, (h, c) = self.encoder(inp)\n",
    "            else:\n",
    "                out, (h, c) = self.encoder(inp, (h, c))\n",
    "            \n",
    "            # last layer(ll) hidden state\n",
    "            h_ll = h[-1:, :, :].permute(1, 0, 2)\n",
    "            h_ll = F.relu(h_ll)\n",
    "            mu, sigma = self.likelihood_layer(h_ll)\n",
    "            mus.append(mu)\n",
    "            sigmas.append(sigma)\n",
    "            if self.likelihood == \"g\":\n",
    "                yin = gaussian_sample(mu, sigma)\n",
    "            elif self.likelihood == \"nb\":\n",
    "                alpha_t = sigma\n",
    "                mu_t = mu\n",
    "                yin = negative_binomial_sample(mu_t, alpha_t)\n",
    "            # if without true value, use prediction\n",
    "            if s >= history and s < horizon + history:\n",
    "                ypred.append(yin)\n",
    "        ypred = torch.cat(ypred, dim=1)\n",
    "        mu = torch.cat(mus, dim=1)\n",
    "        sigma = torch.cat(sigmas, dim=1)\n",
    "        return ypred, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e9751",
   "metadata": {},
   "source": [
    "## Define Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1255e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "\n",
    "args.num_epochs = 1000\n",
    "args.steps_per_epoch = 150\n",
    "args.lr = 5e-3\n",
    "args.n_layers = 3\n",
    "args.hidden_size = 120\n",
    "args.likelihood = \"g\"\n",
    "args.horizon = 24\n",
    "args.history = 24*7\n",
    "args.standard_scaler = True\n",
    "args.log_scaler = False\n",
    "args.mean_scaler = False\n",
    "args.batch_size = 512\n",
    "args.sample_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8ca6c",
   "metadata": {},
   "source": [
    "## Pre-process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21557fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_path = '../../Merged-update_hourly.csv'\n",
    "    data = pd.read_csv(os.path.join(data_path), index_col=0)\n",
    "    data.fillna(0, inplace=True)\n",
    "    known_variables = data.loc[\n",
    "        :, ['WS_S4', 'GATE_S25A', 'GATE_S25B', 'GATE_S25B2', 'PUMP_S25B',\n",
    "            'GATE_S26_1', 'GATE_S26_2', 'PUMP_S26', 'MEAN_RAIN']\n",
    "    ]\n",
    "    unknown_variables = data.loc[\n",
    "        :, ['FLOW_S25A', 'HWS_S25A', 'FLOW_S25B', 'HWS_S25B', 'FLOW_S26',\n",
    "            'HWS_S26']\n",
    "    ]\n",
    "    target_variables = data.loc[\n",
    "        :, ['WS_S1', 'TWS_S25A', 'TWS_S25B', 'TWS_S26']\n",
    "    ]\n",
    "    output_variables = pd.concat([target_variables, unknown_variables], axis=1)\n",
    "    X = known_variables.to_numpy()\n",
    "    y = output_variables.to_numpy()\n",
    "    Xtr, ytr, Xte, yte = util.train_test_split(X, y)\n",
    "    return Xtr, ytr, Xte, yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207291e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, ytr, Xte, yte = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab535042",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d4836",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa655406",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72acc506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, history, horizon, batch_size):\n",
    "    '''Given the dataset, generate a batch for training\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        The input variables\n",
    "    y\n",
    "        The output variables\n",
    "    history\n",
    "        The number of hours of history to input\n",
    "    horizon\n",
    "        The number of hours into the future to output\n",
    "    batch_size\n",
    "        The batch size for training\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple\n",
    "        The \n",
    "    '''\n",
    "    total_time, features = X.shape\n",
    "    if total_time < batch_size:\n",
    "        batch_size = total_time\n",
    "    batch = random.sample(range(history, total_time - horizon), batch_size)\n",
    "    Xp = np.stack([X[idx - history: idx, :] for idx in batch])\n",
    "    yp = np.stack([y[idx - history: idx, :] for idx in batch])\n",
    "    Xf = np.stack([X[idx: idx+horizon, :] for idx in batch])\n",
    "    yf = np.stack([y[idx: idx+horizon, :] for idx in batch])\n",
    "    return Xp, yp, Xf, yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    Xtr,\n",
    "    ytr,\n",
    "    args\n",
    "):\n",
    "    '''Train the model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Xtr\n",
    "        The training dataset\n",
    "    ytr\n",
    "        The target dataset\n",
    "    args\n",
    "        The configuration\n",
    "    '''\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    _, feature_size = Xtr.shape\n",
    "    _, output_size = ytr.shape\n",
    "    model = DeepAR(feature_size, args.hidden_size, output_size,\n",
    "                   args.n_layers, args.likelihood)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)  # use all GPUs\n",
    "    model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=args.lr)\n",
    "    random.seed(2)\n",
    "\n",
    "    yscaler = None\n",
    "    if args.standard_scaler:\n",
    "        yscaler = util.StandardScaler()\n",
    "    elif args.log_scaler:\n",
    "        yscaler = util.LogScaler()\n",
    "    elif args.mean_scaler:\n",
    "        yscaler = util.MeanScaler()\n",
    "    if yscaler is not None:\n",
    "        ytr = yscaler.fit_transform(ytr)\n",
    "\n",
    "    # training\n",
    "    writer = SummaryWriter()\n",
    "    horizon = args.horizon\n",
    "    history = args.history\n",
    "    step = 0\n",
    "    for epoch in tqdm(range(args.num_epochs)):\n",
    "        tqdm.write(\"Epoch {} starts...\".format(epoch))\n",
    "        for step in range(args.steps_per_epoch):\n",
    "            # generate batch\n",
    "            Xp, yp, Xf, yf = batch_generator(\n",
    "                Xtr, ytr, history, horizon, args.batch_size)\n",
    "            Xp = torch.from_numpy(Xp).float().to(device)\n",
    "            yp = torch.from_numpy(yp).float().to(device)\n",
    "            Xf = torch.from_numpy(Xf).float().to(device)\n",
    "            yf = torch.from_numpy(yf).float().to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            ypred, mu, sigma = model(Xp, yp, Xf)\n",
    "            y = torch.cat([yp, yf], dim=1)\n",
    "            if args.likelihood == \"g\":\n",
    "                loss = util.gaussian_likelihood_loss(y, mu, sigma)\n",
    "            elif args.likelihood == \"nb\":\n",
    "                loss = util.negative_binomial_loss(y, mu, sigma)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar('Train/Loss', loss, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e2e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(Xtr, ytr, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c9343",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64a28602",
   "metadata": {},
   "source": [
    "# test\n",
    "mape_list = []\n",
    "# select skus with most top K\n",
    "X_test = Xte[:, -K-n_hours:-\n",
    "             K, :].reshape((num_ts, -1, num_features))\n",
    "Xf_test = Xte[:, -K:, :].reshape((num_ts, -1, num_features))\n",
    "y_test = yte[:, -K-n_hours:-K].reshape((num_ts, -1))\n",
    "yf_test = yte[:, -K:].reshape((num_ts, -1))\n",
    "if yscaler is not None:\n",
    "    y_test = yscaler.transform(y_test)\n",
    "result = []\n",
    "n_samples = args.sample_size\n",
    "for _ in tqdm(range(n_samples)):\n",
    "    y_pred, _, _ = model(X_test, y_test, Xf_test)\n",
    "    y_pred = y_pred.data.numpy()\n",
    "    if yscaler is not None:\n",
    "        y_pred = yscaler.inverse_transform(y_pred)\n",
    "    result.append(y_pred.reshape((-1, 1)))\n",
    "\n",
    "result = np.concatenate(result, axis=1)\n",
    "p50 = np.quantile(result, 0.5, axis=1)\n",
    "p90 = np.quantile(result, 0.9, axis=1)\n",
    "p10 = np.quantile(result, 0.1, axis=1)\n",
    "\n",
    "mape = util.MAPE(yf_test, p50)\n",
    "print(\"P50 MAPE: {}\".format(mape))\n",
    "mape_list.append(mape)\n",
    "\n",
    "if args.show_plot:\n",
    "    plt.figure(1, figsize=(20, 5))\n",
    "    plt.plot([k + K + n_hours - K\n",
    "              for k in range(K)], p50, \"r-\")\n",
    "    plt.fill_between(x=[k + K + n_hours - K\n",
    "                        for k in range(K)],\n",
    "                     y1=p10, y2=p90, alpha=0.5)\n",
    "    plt.title('Prediction uncertainty')\n",
    "    yplot = yte[-1, -K-n_hours:]\n",
    "    plt.plot(range(len(yplot)), yplot, \"k-\")\n",
    "    plt.legend([\"P50 forecast\", \"true\", \"P10-P90 quantile\"],\n",
    "               loc=\"upper left\")\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.vlines(K + n_hours - K, ymin, ymax,\n",
    "               color=\"blue\", linestyles=\"dashed\", linewidth=2)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    plt.show()\n",
    "return losses, mape_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
